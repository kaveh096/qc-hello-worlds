{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8e5353",
   "metadata": {},
   "source": [
    "# Max-Cut Approximation Experiments using QAOA on IBM Quantum Hardware\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook investigates **approximate solutions to the Max-Cut problem** using both **classical** and **quantum** approaches. The primary objective is to assess whether a commercially available quantum computer — specifically an **IBM Quantum backend** — can deliver a *practical advantage* over classical heuristics on small- to mid-scale graphs.\n",
    "\n",
    "I was inspired by the recent **Google Quantum AI** announcement regarding a quantum advantage milestone. I wanted to  see if I can make similar observations in a short amount of time (in a few workdays). Since Google’s *Willow* chip is not publicly available, the next best option was to reproduce a similar test using IBM’s accessible superconducting hardware and compare its QAOA-based performance with classical algorithms on a standard laptop.\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Evaluate **QAOA (Quantum Approximate Optimization Algorithm)** for the Max-Cut problem under realistic hardware conditions.\n",
    "- Compare **quantum** and **classical** performance in terms of:\n",
    "  - Cut quality (direct cut values)\n",
    "  - Execution time (including parameter optimization)\n",
    "- Observe scaling behavior of each algorithm as graph size increases.\n",
    "- Determine if any early signs of *quantum advantage* are observable in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5293e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init library imports and repo path setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add repo root (parent of notebooks/) to sys.path (use resolve for robustness)\n",
    "repo_root = str(Path.cwd().resolve().parent)\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba98e94",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "### Environment\n",
    "- Developed and tested in **VS Code** using **Jupyter** notebooks.\n",
    "- Dependencies are provided in `qaoa_env.yml`.\n",
    "- Uses `networkx` for graph generation and `matplotlib` for plotting.\n",
    "- Quantum simulations and hardware runs are performed via **Qiskit** and **IBM Runtime**.\n",
    "\n",
    "### Graph Model\n",
    "- Undirected graphs with integer edge weights.\n",
    "- Randomly generated via `networkx.gnm_random_graph`.\n",
    "- Typical graph sizes range from **5 to 150 nodes**.\n",
    "\n",
    "## Library Overview: `graphlib.py`\n",
    "\n",
    "This companion module provides:\n",
    "- Core data structures for undirected, weighted graphs.\n",
    "- Functions for generating random graphs and paths.\n",
    "- Implementations of Max-Cut solvers:\n",
    "  - **Exact (brute-force)** — exponential-time reference for small graphs.\n",
    "  - **Classical approximations** — random cut and greedy local search.\n",
    "  - **Quantum approximations** — QAOA (p = 1), both simulated and real hardware.\n",
    "- Integration with **IBM Runtime Sampler** and automatic **transpilation** to match backend constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & basic config\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "from qiskit_aer import AerSimulator\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "import json\n",
    "from lib.graphlib import GraphLib, run_on_ibm_runtime\n",
    "\n",
    "service = QiskitRuntimeService(name=\"default-ibm-quantum-platform\")\n",
    "\n",
    "# Notebook defaults\n",
    "AER_BACKEND = AerSimulator()\n",
    "QAOA_SHOTS = 4096  # simulator shots for validating angles\n",
    "EDGE_PROB = 0.3\n",
    "WEIGHT_RANGE = (1, 20)\n",
    "REPEATS = 5  # Repeats per size\n",
    "PARTIAL_RESULT_PATH = Path(\n",
    "    repo_root + \"/data/maxcut_qaoa_partial_results.jsonl\")\n",
    "\n",
    "# Sweep sizes (you can change / expand)\n",
    "MAX_SIZE_FOR_OPT = 20  # max n for which we compute optimal cuts via brute-force\n",
    "MAX_SIZE_FOR_AER = 28  # max n for which we run the simulator (AER)\n",
    "SIZE_RANGE = list(range(5, 150, 2))\n",
    "\n",
    "# For plotting aesthetics\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4206155",
   "metadata": {},
   "source": [
    "## Classical Approaches\n",
    "\n",
    "The classical baseline includes:\n",
    "- **Brute-force solver**: Computes the global optimum for graphs up to ~20 nodes. Used as a correctness and performance benchmark.\n",
    "- **Random cut**: Assigns random bitstring partitions; establishes a stochastic baseline.\n",
    "- **Local search (greedy)**: Iteratively improves an initial cut by flipping bits to increase the cut value.\n",
    "\n",
    "Each classical method is timed and evaluated for accuracy and scalability.\n",
    "\n",
    "## Quantum Simulation: QAOA on Aer\n",
    "\n",
    "The **QAOA simulation** uses `Qiskit Aer` to execute noiseless circuits corresponding to the cost and mixer Hamiltonians for Max-Cut. This allows us to test algorithmic performance without hardware noise.\n",
    "\n",
    "Key parameters:\n",
    "- **p = 1** (single-layer QAOA)\n",
    "- **Shots = 4096**\n",
    "- **Classical parameter optimization** via analytic expectation minimization (`optimize_qaoa1_classical`)\n",
    "\n",
    "Results show that simulated QAOA achieves **comparable cut values** to classical heuristics, though at higher runtime due to circuit simulation and optimization overhead. But the simulation does not scale to higher number of qubits.\n",
    "\n",
    "## Real Hardware: QAOA on IBM Quantum Devices\n",
    "\n",
    "After validating the simulation pipeline, the same circuits were executed on a real **IBM Quantum backend** using the **Qiskit Runtime Sampler API**. Circuits were automatically transpiled using `generate_preset_pass_manager` with optimization level 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae49e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to run one graph instance and return results as dict\n",
    "def run_qc_instance(g):\n",
    "    available_backends = [b for b in service.backends(\n",
    "    ) if b.configuration().n_qubits >= g.G.number_of_nodes() and b.status().operational]\n",
    "    backend_name = sorted(available_backends,\n",
    "                          key=lambda b: b.status().pending_jobs)[0].name\n",
    "    # --- build graph and QAOA circuit\n",
    "    t0 = time.time()\n",
    "    gamma, beta, _, _ = g.optimize_qaoa1_classical(grid_res=21, refine=True)\n",
    "    qc = g.build_qaoa1_circuit(gamma, beta)\n",
    "    qc.measure_all()\n",
    "\n",
    "    # --- run on hardware via IBM Runtime\n",
    "    job = run_on_ibm_runtime(\n",
    "        [qc], backend_name=backend_name, shots=QAOA_SHOTS, service=service)\n",
    "    t1 = time.time()\n",
    "    return job, t1-t0\n",
    "\n",
    "\n",
    "def run_single_instance(n, run_qc, edge_prob=EDGE_PROB, weight_range=WEIGHT_RANGE, shots=QAOA_SHOTS):\n",
    "    \"\"\"\n",
    "    Generate a random graph with n nodes and run:\n",
    "      - classical approximations (random, local search)\n",
    "      - qaoa p=1 analytic optimize + simulated validation (shots)\n",
    "      - optional brute-force exact optimum if compute_optimal True\n",
    "    Returns a dict with values and timings.\n",
    "    \"\"\"\n",
    "    g = GraphLib()\n",
    "    g.generate_random_graph(\n",
    "        num_vertices=n, edge_prob=edge_prob, weight_range=weight_range)\n",
    "\n",
    "    out = {'n': n, 'g': g}\n",
    "    # Classical random approx\n",
    "    t0 = time.time()\n",
    "    _, w_rand = g.max_cut_random(trials=2000)\n",
    "    t_rand = time.time() - t0\n",
    "    out.update({'rand_cut': w_rand, 'rand_time': t_rand})\n",
    "\n",
    "    # Classical local search approx\n",
    "    t0 = time.time()\n",
    "    _, w_local = g.max_cut_local_search(iterations=200)\n",
    "    t_local = time.time() - t0\n",
    "    out.update({'local_cut': w_local, 'local_time': t_local})\n",
    "\n",
    "    # Brute force optimal if allowed for small n\n",
    "    if n <= MAX_SIZE_FOR_OPT:\n",
    "        t0 = time.time()\n",
    "        _, w_opt = g.max_cut_bruteforce()\n",
    "        t_opt = time.time() - t0\n",
    "        out.update({'opt_cut': w_opt, 'opt_time': t_opt})\n",
    "    else:\n",
    "        out.update({'opt_cut': None, 'opt_time': None})\n",
    "    # Reset remaining QAOA fields\n",
    "    out.update({\n",
    "        'qaoa_gamma': None, 'qaoa_beta': None,\n",
    "        'qaoa_analytic_val': None, 'qaoa_opt_time': None,\n",
    "        'qaoa_sampled_expectation': None, 'qaoa_best_cut': None,\n",
    "        'qaoa_counts': None, 'qaoa_sim_time': None,\n",
    "        'qaoa_total_time': None,\n",
    "        'qaoa_shots': None,\n",
    "        'qc_job': None, 'qc_prep_time': None, 'qc_run_time': None,\n",
    "        'qc_best_cut': None, 'qc_total_time': None\n",
    "    })\n",
    "    if (n <= MAX_SIZE_FOR_AER):\n",
    "        # Simulator backend feasible only for small n\n",
    "        # QAOA p=1: analytic optimization (fast)\n",
    "        t0 = time.time()\n",
    "        gamma_star, beta_star, val_star, _ = g.optimize_qaoa1_classical(\n",
    "            grid_res=21, refine=True)\n",
    "        t_qaoa_opt = time.time() - t0\n",
    "        out.update({'qaoa_gamma': gamma_star, 'qaoa_beta': beta_star,\n",
    "                    'qaoa_analytic_val': val_star, 'qaoa_opt_time': t_qaoa_opt})\n",
    "\n",
    "        # Validate via simulator (shots)\n",
    "        t0 = time.time()\n",
    "        res = g.qaoa1_expectation_simulated(\n",
    "            gamma_star, beta_star, shots=shots, backend=AER_BACKEND)\n",
    "        t_qaoa_sim = time.time() - t0\n",
    "        # res includes 'expectation' (sampled average), 'best_cut' (best sample)\n",
    "        out.update({\n",
    "            'qaoa_sampled_expectation': res['expectation'],\n",
    "            'qaoa_best_cut': res['best_cut'],\n",
    "            # 'qaoa_counts': res['counts'],  # Skip large array\n",
    "            'qaoa_sim_time': t_qaoa_sim,\n",
    "            'qaoa_total_time': t_qaoa_sim + t_qaoa_opt,\n",
    "            'qaoa_shots': shots\n",
    "        })\n",
    "    if (run_qc):\n",
    "        # Going to run the graph on real QC hardware\n",
    "        job, timing = run_qc_instance(g)\n",
    "        out.update({'qc_job': job, 'qc_prep_time': timing})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous partial-results file so a full top-to-bottom run starts fresh\n",
    "PARTIAL_RESULT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "if PARTIAL_RESULT_PATH.exists():\n",
    "    PARTIAL_RESULT_PATH.unlink()\n",
    "    print(f\"Removed existing partial results: {PARTIAL_RESULT_PATH}\")\n",
    "else:\n",
    "    print(f\"No partial results to remove at: {PARTIAL_RESULT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep driver that runs multiple repeats per n and collects results\n",
    "def sweep_ns(ns_list, repeats=REPEATS, partial_result_path=PARTIAL_RESULT_PATH):\n",
    "    rows = []\n",
    "    # Single outer progress bar over graph sizes; update its description to show current size & repeat\n",
    "    outer = trange(len(ns_list), desc=\"n=\")\n",
    "    for idx in outer:\n",
    "        n = ns_list[idx]\n",
    "        for r in range(repeats):\n",
    "            try:\n",
    "                # Update outer progress bar description to show current graph size and repeat number\n",
    "                outer.set_description(f\"n={n} r={r+1}/{repeats}\")\n",
    "                # We run on real hardware with only one repeat to save on resources\n",
    "                row = run_single_instance(\n",
    "                    n, run_qc=(r == 0), edge_prob=EDGE_PROB, weight_range=WEIGHT_RANGE, shots=QAOA_SHOTS)\n",
    "                row['repeat'] = r\n",
    "                rows.append(row)\n",
    "                # append to disk incrementally\n",
    "                with partial_result_path.open(\"a\") as f:\n",
    "                    f.write(json.dumps(row, default=str) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Instance failed for n={n}, repeat={r}: {e}\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df, rows\n",
    "\n",
    "\n",
    "# Run the sweep (this will take time depending on NS_ALL and repeats)\n",
    "df, rows = sweep_ns(SIZE_RANGE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for all real hardware jobs to complete and collect their results\n",
    "for i, row in enumerate(rows):\n",
    "    job = row['qc_job']\n",
    "    if job is not None:\n",
    "        print(f\"Waiting for job {i} (n={row['n']}) to complete...\")\n",
    "        exec_span = job.result().metadata[\"execution\"][\"execution_spans\"][0]\n",
    "        qc_run_time = exec_span.stop - exec_span.start\n",
    "        counts = job.result()[0].data.meas.get_counts()\n",
    "        if counts:\n",
    "            best_bitstring = max(counts, key=counts.get)\n",
    "            best_cut = row['g'].cut_value_from_bitstring(best_bitstring)\n",
    "\n",
    "            freqs = np.array(list(counts.values()), dtype=float)\n",
    "            freqs = freqs / freqs.sum()\n",
    "            print(\"\\tfrac ones:   \", sum(\n",
    "                1 for v in counts.values() if v == 1) / len(counts))\n",
    "            print(\"\\tentropy bits:\", entropy(freqs, base=2))\n",
    "        else:\n",
    "            best_cut = None\n",
    "        # Update the row dict\n",
    "        # row['qc_counts'] = counts  # huge array, skip storing\n",
    "        row['qc_best_cut'] = best_cut\n",
    "        row['qc_run_time'] = qc_run_time.total_seconds()\n",
    "        row['qc_total_time'] = row['qc_prep_time'] + \\\n",
    "            qc_run_time.total_seconds()\n",
    "        # Update the DataFrame as well\n",
    "        df.at[i, 'qc_total_time'] = row['qc_total_time']\n",
    "        df.at[i, 'qc_run_time'] = row['qc_run_time']\n",
    "        df.at[i, 'qc_best_cut'] = best_cut\n",
    "    else:\n",
    "        df.at[i, 'qc_best_cut'] = None\n",
    "        df.at[i, 'qc_run_time'] = None\n",
    "        df.at[i, 'qc_total_time'] = None\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193e7ff",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- Real hardware runs successfully executed up to **150 nodes**, with measured execution time of **a few seconds** (excluding queue delays). It shows the runtime can scale to much larger graphs as we get more qubits.\n",
    "- Queue delays (often several hours) dominate total turnaround time but are excluded from performance analysis.\n",
    "- I have plotted the runtimes excluding the parameter optimization step (my laptop running `optimize_qaoa1_classical`) and once including everything.\n",
    "\n",
    "### Results Summary\n",
    "- The **quantum hardware runs** produced valid results but with **lower cut values** than classical.\n",
    "- Cut values fluctuate sharply with graph size — a **jagged curve** indicative of noise, calibration drift, or decoherence.\n",
    "- Count distributions contain many unique bitstrings with frequency 1, suggesting **high output entropy** and **low SNR**.\n",
    "\n",
    "Despite these limitations, execution times (excluding queue delays) are competitive, showing potential once fidelity improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dabb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute aggregated metrics per n and algorithm; compute aggregates\n",
    "def compute_aggregates(df):\n",
    "    # Ensure we have a count per group\n",
    "    counts = df.groupby(\"n\").size().rename(\"count\").reset_index()\n",
    "    # Use named aggregations for clarity\n",
    "    agg = df.groupby(\"n\").agg(\n",
    "        opt_cut_mean=(\"opt_cut\", \"mean\"),\n",
    "        opt_cut_std=(\"opt_cut\", \"std\"),\n",
    "        rand_cut_mean=(\"rand_cut\", \"mean\"),\n",
    "        rand_cut_std=(\"rand_cut\", \"std\"),\n",
    "        local_cut_mean=(\"local_cut\", \"mean\"),\n",
    "        local_cut_std=(\"local_cut\", \"std\"),\n",
    "        qaoa_best_cut_mean=(\"qaoa_best_cut\", \"mean\"),\n",
    "        qaoa_best_cut_std=(\"qaoa_best_cut\", \"std\"),\n",
    "        qc_best_cut_mean=(\"qc_best_cut\", \"mean\"),\n",
    "        qc_best_cut_std=(\"qc_best_cut\", \"std\"),\n",
    "        rand_time_mean=(\"rand_time\", \"mean\"),\n",
    "        rand_time_std=(\"rand_time\", \"std\"),\n",
    "        local_time_mean=(\"local_time\", \"mean\"),\n",
    "        local_time_std=(\"local_time\", \"std\"),\n",
    "        qaoa_total_time_mean=(\"qaoa_total_time\", \"mean\"),\n",
    "        qaoa_total_time_std=(\"qaoa_total_time\", \"std\"),\n",
    "        qc_total_time_mean=(\"qc_total_time\", \"mean\"),\n",
    "        qc_total_time_std=(\"qc_total_time\", \"std\"),\n",
    "        qc_run_time_mean=(\"qc_run_time\", \"mean\"),\n",
    "        qc_run_time_std=(\"qc_run_time\", \"std\"),\n",
    "        opt_time_mean=(\"opt_time\", \"mean\"),\n",
    "        opt_time_std=(\"opt_time\", \"std\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # attach counts and compute SEM using per-group counts\n",
    "    agg = agg.merge(counts, on=\"n\", how=\"left\")\n",
    "\n",
    "    for col_prefix in [\n",
    "        \"opt_cut\",\n",
    "        \"rand_cut\",\n",
    "        \"local_cut\",\n",
    "        \"qaoa_best_cut\",\n",
    "        \"qc_best_cut\",\n",
    "        \"rand_time\",\n",
    "        \"local_time\",\n",
    "        \"qaoa_total_time\",\n",
    "        \"qc_total_time\",\n",
    "        \"qc_run_time\",\n",
    "        \"opt_time\",\n",
    "    ]:\n",
    "        std_col = f\"{col_prefix}_std\"\n",
    "        sem_col = f\"{col_prefix}_sem\"\n",
    "        # treat NaN std (e.g., single sample) as 0 so SEM becomes 0\n",
    "        std_vals = agg[std_col].fillna(0)\n",
    "        agg[sem_col] = std_vals / np.sqrt(agg[\"count\"].replace(0, np.nan))\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "agg_df = compute_aggregates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9871cb0",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "This section presents runtime scaling and cut value comparisons for all algorithms:\n",
    "- **Runtime vs. number of nodes** (log-scale)\n",
    "- **Mean cut value ± SEM** vs. number of nodes\n",
    "\n",
    "The visual results highlight the trade-offs:\n",
    "- Classical algorithms scale smoothly and predictably.\n",
    "- Simulated QAOA matches classical results but is slower.\n",
    "- Real hardware results vary widely — evidence of decoherence and readout noise effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut value plots with error bars using precomputed std columns\n",
    "def plot_cut_values(agg_df):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    def errplot(x, y, yerr, label, **kwargs):\n",
    "        plt.errorbar(x, y, yerr=yerr, fmt='-o', markersize=6, markeredgewidth=0.8,\n",
    "                     capsize=4, label=label, **kwargs)\n",
    "\n",
    "    errplot(agg_df['n'], agg_df['opt_cut_mean'],\n",
    "            agg_df['opt_cut_sem'], 'Optimal (brute-force)')\n",
    "    errplot(agg_df['n'], agg_df['rand_cut_mean'],\n",
    "            agg_df['rand_cut_sem'], 'Random (classical)')\n",
    "    errplot(agg_df['n'], agg_df['local_cut_mean'],\n",
    "            agg_df['local_cut_sem'], 'Local search (classical)')\n",
    "    errplot(agg_df['n'], agg_df['qaoa_best_cut_mean'],\n",
    "            agg_df['qaoa_best_cut_sem'], 'QAOA Sim (sampled best)')\n",
    "    errplot(agg_df['n'], agg_df['qc_best_cut_mean'],\n",
    "            agg_df['qc_best_cut_sem'], 'QAOA Real (sampled best)')\n",
    "\n",
    "    plt.xlabel('n (number of nodes)')\n",
    "    plt.ylabel('Cut value (mean ± SEM)')\n",
    "    plt.title('Max-Cut algo comparison: classical vs quantum (mean ± SEM)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cut_values(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation ratio plots with error bars using precomputed std columns\n",
    "def plot_approximation_ratios(agg_df):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    def ratioplot(x, y, label, **kwargs):\n",
    "        plt.errorbar(x, y, yerr=None, fmt='-o', markersize=6, markeredgewidth=0.8,\n",
    "                     capsize=4, label=label, **kwargs)\n",
    "\n",
    "    ratioplot(agg_df['n'], agg_df['opt_cut_mean'] /\n",
    "              agg_df['rand_cut_mean'], 'Optimal (brute-force)')\n",
    "    ratioplot(agg_df['n'],agg_df['rand_cut_mean'] /\n",
    "              agg_df['rand_cut_mean'], 'Baseline (Random algo)')\n",
    "    ratioplot(agg_df['n'], agg_df['local_cut_mean'] /\n",
    "              agg_df['rand_cut_mean'], 'Local search (classical)')\n",
    "    ratioplot(agg_df['n'], agg_df['qaoa_best_cut_mean'] /\n",
    "              agg_df['rand_cut_mean'], 'QAOA Sim (sampled best)')\n",
    "    ratioplot(agg_df['n'], agg_df['qc_best_cut_mean'] /\n",
    "              agg_df['rand_cut_mean'], 'QAOA Real (sampled best)')\n",
    "\n",
    "    plt.xlabel('n (number of nodes)')\n",
    "    plt.ylabel('Cut value relative to random algo')\n",
    "    plt.title('Max-Cut approximation comparison: Higher is better')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_approximation_ratios(agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397af3c6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It is **not yet obvious** from these experiments that quantum hardware provides an approximation advantage for Max-Cut under current conditions. Or at least I cannot reproduce it. The hardware-generated cut values are often lower than classical approximations, and noise remains the primary limiting factor.\n",
    "\n",
    "However, there is clear **promise**:\n",
    "- Hardware execution time (excluding queue latency) is short and stable.\n",
    "- With improved coherence times, reduced readout errors, and **hardware-aware parameter optimization**, we may expect significantly better cut quality.\n",
    "\n",
    "I have a lot more to lerarn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469380ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime plots with error bars (log scale)\n",
    "def plot_runtimes(agg_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    def errplot(x, ymean, yerr, label, **kwargs):\n",
    "        plt.errorbar(x, ymean, yerr=yerr, fmt='-o', markersize=6, markeredgewidth=0.8,\n",
    "                     capsize=4, label=label, **kwargs)\n",
    "\n",
    "    errplot(agg_df['n'], agg_df['opt_time_mean'],\n",
    "            agg_df['opt_time_sem'], 'Brute-force optimal')\n",
    "    errplot(agg_df['n'], agg_df['rand_time_mean'],\n",
    "            agg_df['rand_time_sem'], 'Random (classical)')\n",
    "    errplot(agg_df['n'], agg_df['local_time_mean'],\n",
    "            agg_df['local_time_sem'], 'Local search (classical)')\n",
    "    errplot(agg_df['n'], agg_df['qaoa_total_time_mean'],\n",
    "            agg_df['qaoa_total_time_sem'], f'QAOA Sim Total (shots={QAOA_SHOTS})')\n",
    "    errplot(agg_df['n'], agg_df['qc_total_time_mean'],\n",
    "            agg_df['qc_total_time_sem'], f'QAOA Real Total (shots={QAOA_SHOTS})')\n",
    "    errplot(agg_df['n'], agg_df['qc_run_time_mean'],\n",
    "            agg_df['qc_run_time_sem'], f'QAOA Real (QC time only)')\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('n (nodes)')\n",
    "    plt.ylabel('Runtime (seconds, log scale, ± SEM)')\n",
    "    plt.title('Algorithm runtimes vs graph size (mean ± SEM)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_runtimes(agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3680c509",
   "metadata": {},
   "source": [
    "## Known Limitations\n",
    "\n",
    "- Limited to **p = 1**; multi-layer QAOA not yet implemented.\n",
    "- **Analytic optimization** assumes noiseless expectations.\n",
    "- Only one hardware job per graph size (cost control) — limited statistics.\n",
    "- IBM Queue delays excluded from timing.\n",
    "- No explicit error mitigation applied.\n",
    "- Hardware runs unreliable beyond ~100 qubits due to depth and mapping.\n",
    "\n",
    "## Future Directions\n",
    "\n",
    "- Extend to multi-layer QAOA (p > 1) and hybrid optimizers.\n",
    "- Integrate readout-error mitigation and dynamic qubit selection.\n",
    "- Implement **hardware-in-the-loop optimization** (SPSA, COBYLA).\n",
    "- Explore scaling trends across multiple IBM Quantum backends.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Farhi et al., *“A Quantum Approximate Optimization Algorithm,”* arXiv:1411.4028 (2014).  \n",
    "2. IBM Quantum Runtime Documentation – [https://quantum.ibm.com/docs/](https://quantum.ibm.com/docs/)  \n",
    "3. Qiskit Transpilation Guide – [https://quantum.ibm.com/docs/guides/transpile](https://quantum.ibm.com/docs/guides/transpile)  \n",
    "4. Google Quantum AI, *“Demonstrating quantum advantage with the Willow processor,”* Nature (2025).  \n",
    "5. NetworkX Documentation – [https://networkx.org](https://networkx.org)\n",
    "6. Wang et al., \"Quantum Approximate Optimization Algorithm for MaxCut: A Fermionic View\", https://arxiv.org/pdf/1706.02998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ac59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw and aggregated results (optional)\n",
    "df.to_csv('../data/maxcut_qaoa_raw_results.csv', index=False)\n",
    "agg_df.to_csv('../data/maxcut_qaoa_aggregates.csv', index=False)\n",
    "print(\"Saved CSVs: raw and aggregates.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
